{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0f4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o dataframe\n",
    "# Primeira análise apenas com extroversão\n",
    "data_path = \"../chalearn_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13681bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>extraversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zEyRyTnIw5I.005.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nskJh7v6v1U.004.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eHcRre1YsNA.000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VuadgOz6T7s.000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7nhJXn9PI0I.001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>9yZEb6bdxNY.004.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>dNXqs5HNijI.004.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>rG8D-A2F8xg.004.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>F-Dy1EFm_Mw.005.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>UOvgGSx9k_k.002.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0  extraversion\n",
       "0     zEyRyTnIw5I.005.mp4             0\n",
       "1     nskJh7v6v1U.004.mp4             0\n",
       "2     eHcRre1YsNA.000.mp4             0\n",
       "3     VuadgOz6T7s.000.mp4             0\n",
       "4     7nhJXn9PI0I.001.mp4             0\n",
       "...                   ...           ...\n",
       "1995  9yZEb6bdxNY.004.mp4             1\n",
       "1996  dNXqs5HNijI.004.mp4             1\n",
       "1997  rG8D-A2F8xg.004.mp4             1\n",
       "1998  F-Dy1EFm_Mw.005.mp4             1\n",
       "1999  UOvgGSx9k_k.002.mp4             1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_training = pd.read_csv(f\"{data_path}/train/extraversion_data.csv\")\n",
    "df_training = pd.DataFrame.from_dict(data_training)\n",
    "\n",
    "df_training.head(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07405537",
   "metadata": {},
   "source": [
    "## Implementando um primeiro modelo\n",
    "\n",
    "EfficientNet B0 -> Transformers -> Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8c0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c65b4f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,049,571\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Camadas iniciais do modelo:\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)) # Por enquanto o input é apenas uma imagem\n",
    "# Usa EfficientNet B0 como extratora de características da imagem que iremos processar\n",
    "features_extraction = EfficientNetB0(include_top=False, weights='imagenet')\n",
    "features_extraction.trainable = False\n",
    "features_extraction = features_extraction(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs, features_extraction)\n",
    "# model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "616db9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers - Camada final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8370b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_dim):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_dim = patch_dim\n",
    "\n",
    "    def call(self, tensors):\n",
    "        batch_size = tf.shape(tensors)[0]\n",
    "        patches = tf.reshape(tensors, [batch_size, -1, patch_dim])\n",
    "        print(\"Patches shape = \", patches.shape)\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "419273c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Já temos um patch projetado linearmente, só precisamos agora fazer o embedding\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, num_patches, patch_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=patch_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = patch + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a355b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_classifier():\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "#     # Augment data.\n",
    "#     augmented = data_augmentation(inputs)\n",
    "#     # Create patches.\n",
    "#     patches = Patches(patch_size)(augmented)\n",
    "#     # Encode patches.\n",
    "#     encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "#     # Create multiple layers of the Transformer block.\n",
    "#     for _ in range(transformer_layers):\n",
    "#         # Layer normalization 1.\n",
    "#         x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "#         # Create a multi-head attention layer.\n",
    "#         attention_output = layers.MultiHeadAttention(\n",
    "#             num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "#         )(x1, x1)\n",
    "#         # Skip connection 1.\n",
    "#         x2 = layers.Add()([attention_output, encoded_patches])\n",
    "#         # Layer normalization 2.\n",
    "#         x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "#         # MLP.\n",
    "#         x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "#         # Skip connection 2.\n",
    "#         encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "#     # Create a [batch_size, projection_dim] tensor.\n",
    "#     representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "#     representation = layers.Flatten()(representation)\n",
    "#     representation = layers.Dropout(0.5)(representation)\n",
    "#     # Add MLP.\n",
    "#     features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "#     # Classify outputs.\n",
    "#     logits = layers.Dense(num_classes)(features)\n",
    "#     # Create the Keras model.\n",
    "#     model = keras.Model(inputs=inputs, outputs=logits)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fd3c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches shape =  (None, None, 64)\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
      "                                                                 \n",
      " patches_5 (Patches)         (None, None, 64)          0         \n",
      "                                                                 \n",
      " encoder_2 (Encoder)         (None, 20, 64)            1280      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,050,851\n",
      "Trainable params: 1,280\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Camadas iniciais do modelo:\n",
    "patch_dim = 64\n",
    "num_patches = 1280 // patch_dim\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)) # Por enquanto o input é apenas uma imagem\n",
    "# Usa EfficientNet B0 como extratora de características da imagem que iremos processar\n",
    "features_extraction = EfficientNetB0(include_top=False, weights='imagenet')\n",
    "features_extraction.trainable = False\n",
    "features_extraction = features_extraction(inputs)\n",
    "# Patches\n",
    "patches = Patches(patch_dim)(features_extraction)\n",
    "\n",
    "# Encodding\n",
    "encoded_patches = Encoder(num_patches, patch_dim)(patches)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs, encoded_patches)\n",
    "# model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
